{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'n02112137-chow', 1: 'n02085782-Japanese_spaniel', 2: 'human', 3: 'model3.h5', 4: 'n02110958-pug'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/rupesh/Downloads/laravel-9-multi-auth-system-main/Test2') \n",
    "classes = os.listdir()\n",
    "d = dict(zip(range(len(classes)),classes))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1237 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/rupesh/Downloads/laravel-9-multi-auth-system-main/Test2',  # This is the source directory for training images\n",
    "        target_size=(100, 100),  # All images will be resized to 100 x 100\n",
    "        batch_size=batch_size,\n",
    "    \n",
    "        # Specify the classes explicitly ##classes = 16, Here We have 16 Classes\n",
    "#         classes = ['n02089867-Walker_hound', 'n02099601-golden_retriever', 'n02106550-Rottweiler'],\n",
    "        classes = ['n02110958-pug', 'n02085782-Japanese_spaniel', 'n02112137-chow', 'human'],\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 49, 49, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 526,244\n",
      "Trainable params: 526,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 100x 100 with 3 bytes color\n",
    "    # The first convolution\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    \n",
    "    # 5 output neurons for 5 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:10:14.677384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 18s 472ms/step - loss: 1.3056 - acc: 0.5162\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 19s 481ms/step - loss: 1.2206 - acc: 0.5311\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 20s 531ms/step - loss: 1.0884 - acc: 0.5635\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 19s 497ms/step - loss: 0.9460 - acc: 0.6141\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 19s 509ms/step - loss: 0.8563 - acc: 0.6631\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 21s 547ms/step - loss: 0.7551 - acc: 0.6954\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.7091 - acc: 0.7286\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 19s 506ms/step - loss: 0.6023 - acc: 0.7577\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 19s 514ms/step - loss: 0.5318 - acc: 0.7934\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 19s 499ms/step - loss: 0.4849 - acc: 0.8207\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 20s 542ms/step - loss: 0.4201 - acc: 0.8432\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 20s 534ms/step - loss: 0.3047 - acc: 0.8979\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 21s 539ms/step - loss: 0.2808 - acc: 0.9037\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 0.1555 - acc: 0.9444\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 20s 528ms/step - loss: 0.1722 - acc: 0.9344\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 21s 540ms/step - loss: 0.1434 - acc: 0.9544\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.1254 - acc: 0.9660\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 21s 547ms/step - loss: 0.1052 - acc: 0.9710\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 21s 546ms/step - loss: 0.0909 - acc: 0.9751\n",
      "Epoch 20/20\n",
      "19/38 [==============>...............] - ETA: 10s - loss: 0.1386 - acc: 0.9531"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "total_sample=train_generator.n\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch=int(total_sample/batch_size),  \n",
    "        epochs=n_epochs,\n",
    "        verbose=1)\n",
    "\n",
    "model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample=train_generator.n\n",
    "print(total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model3.h5')\n",
    "\n",
    "test_image = image.load_img('/home/rupesh/Downloads/laravel-9-multi-auth-system-main/Test2/n02085782-Japanese_spaniel/n02085782_313.jpg', target_size = (100,100))\n",
    "imageplot = plt.imshow(test_image)\n",
    "x = image.img_to_array(test_image)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "result = model.predict(images, batch_size=10)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    print(\"This is a Pug\")    \n",
    "elif result[0][1] == 1:\n",
    "    print(\"This is a Japanese spaniel\")\n",
    "elif result[0][2] == 1:\n",
    "    print(\"This is a Chow\")\n",
    "elif result[0][3] == 1:\n",
    "    print(\"This is human\")\n",
    "else:\n",
    "    print(\"Sorry\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
